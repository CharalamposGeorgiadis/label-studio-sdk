{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this example to write a Python script that performs active learning with a machine learning model. Active learning is a branch of machine learning that seeks to minimize the total amount of data required for labeling by strategically sampling data that provides insight into the problem you're trying to solve so that you can focus on labeling that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Studio API connection configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_STUDIO_URL = 'http://localhost:8000'\n",
    "API_KEY = 'd6f8a2622d39e9d89ff0dfef1a80ad877f4ee9e3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check connection to running Label Studio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'UP'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from label_studio_sdk import Client\n",
    "\n",
    "ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "ls.check_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!! Uncertainty sampling\n"
     ]
    }
   ],
   "source": [
    "from label_studio_sdk.project import ProjectSampling\n",
    "\n",
    "project = ls.start_project(\n",
    "    title='AL Project Created from SDK',\n",
    "    label_config='''\n",
    "    <View>\n",
    "    <Text name=\"text\" value=\"$text\"/>\n",
    "    <Choices name=\"sentiment\" toName=\"text\" choice=\"single\" showInLine=\"true\">\n",
    "        <Choice value=\"Positive\"/>\n",
    "        <Choice value=\"Negative\"/>\n",
    "        <Choice value=\"Neutral\"/>\n",
    "    </Choices>\n",
    "    </View>\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Active Learning scenario, we need to set \"Uncertainty Sampling\", that automatically reorder tasks according to the lowest prediction scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_sampling(ProjectSampling.UNCERTAINTY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's play with a very simple TF-IDF Text Classification model built on top of scikit-learn API. To perform Active Learning, we have to be able to retrain model weights and make the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "labels_map = {\n",
    "    'Positive': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2\n",
    "}\n",
    "inv_labels_map = {idx: label for label, idx in labels_map.items()}\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    # Initialize model with random weights\n",
    "    return make_pipeline(TfidfVectorizer(), LogisticRegression(C=10, verbose=True))\n",
    "\n",
    "\n",
    "def train_model(model, input_texts, output_labels):\n",
    "    # Train the model, given list of input texts and output labels\n",
    "    model.fit(input_texts, [labels_map[label] for label in output_labels])\n",
    "\n",
    "\n",
    "def get_model_predictions(model, input_texts):\n",
    "    # Make model inference and return predicted labels and associated prediction scores\n",
    "    probabilities = model.predict_proba(input_texts)\n",
    "    predicted_label_indices = np.argmax(probabilities, axis=1)\n",
    "    predicted_scores = probabilities[np.arange(len(predicted_label_indices)), predicted_label_indices]\n",
    "    return [inv_labels_map[i] for i in predicted_label_indices], predicted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active learning step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's collect tasks from Label Studio that have been labeled so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_tasks = project.get_labeled_tasks()\n",
    "texts, labels = [], []\n",
    "for labeled_task in labeled_tasks:\n",
    "    texts.append(labeled_task['data']['text'])\n",
    "    labels.append(labeled_task['annotations'][0]['result'][0]['value']['choices'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update model weights based on labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, texts, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now collect unlabeled data from Label Studio. Since unlabeled pool could be large, to reduce complexity we can sample and retrieve only small subset of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_tasks_ids = project.get_unlabeled_tasks_ids()\n",
    "batch_ids = random.sample(unlabeled_tasks_ids, 10)\n",
    "unlabeled_tasks = project.get_tasks(selected_ids=batch_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make model inference for extracted tasks subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [task['data']['text'] for task in unlabeled_tasks]\n",
    "pred_labels, pred_scores = get_model_predictions(model, texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally plug model predictions back to Label Studio. Let's call this model version based on the amount of data used to retrain, but it actually could be any arbitrary unique name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = f'model_{len(labeled_tasks)}'\n",
    "predictions = []\n",
    "for task, pred_label, pred_score in zip(unlabeled_tasks, pred_labels, pred_scores):\n",
    "    project.create_prediction(\n",
    "        task_id=task['id'],\n",
    "        result=[{\n",
    "            'from_name': 'sentiment',\n",
    "            'to_name': 'text',\n",
    "            'type': 'choices',\n",
    "            'value': {\n",
    "                'choices': [pred_label]\n",
    "            }\n",
    "        }],\n",
    "        score=pred_score,\n",
    "        model_version=model_version\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing is to tell Label Studio to use the last created model version as a source for uncertainty sampling and preannotations to be shown to the labelers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.set_model_version(model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now it's easy to create AL loop by iterating Active Learning step from time to time. You can also make this in event-driven way when new portion of annotations created by using Label Studio Webhooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django-env-kernel",
   "language": "python",
   "name": "django-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
